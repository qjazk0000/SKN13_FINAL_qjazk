"""
RAG ì‹œìŠ¤í…œ í†µí•© íŒŒì´í”„ë¼ì¸
ì „ì²´ RAG ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° êµ¬ì¡°ë¥¼ í™œìš©í•œ í–¥ìƒëœ ê²€ìƒ‰ê³¼ ë‹µë³€ ìƒì„±
"""

from typing import List, Dict, Any, Optional
from django.conf import settings
from .keyword_extractor import extract_keywords
from .filters import guess_domains_from_keywords
from .rag_search import RagSearcher
from .answerer import make_answer, format_context_for_display, validate_answer_quality
import datetime
import re
import os
import sys
import time
import logging
import openai
import hashlib

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# í”„ë¡¬í”„íŠ¸ ë¡œë” ì§ì ‘ êµ¬í˜„
def load_prompt(path: str, *, default: str = "") -> str:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if not os.path.exists(path):
        return default
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        print(f"WARNING: Failed to load prompt from {path}: {e}")
        return default

# ì „ì—­ í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜
_SYSTEM_PROMPT = None
_USER_PROMPT = None

def _init_prompts():
    """í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜"""
    global _SYSTEM_PROMPT, _USER_PROMPT
    
    if _SYSTEM_PROMPT is None:
        try:
            system_prompt_path = '/app/config/system_prompt.md'
            _SYSTEM_PROMPT = load_prompt(system_prompt_path,
                                         default="ë‹¹ì‹ ì€ ì—…ë¬´ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
        except FileNotFoundError:
            _SYSTEM_PROMPT = "ë‹¹ì‹ ì€ ì—…ë¬´ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            print("WARNING: system_prompt.md not found, using default prompt")
    
    if _USER_PROMPT is None:
        try:
            user_prompt_path = '/app/config/user_prompt.md'
            _USER_PROMPT = load_prompt(user_prompt_path,
                                       default="ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
        except FileNotFoundError:
            _USER_PROMPT = "ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
            print("WARNING: user_prompt.md not found, using default prompt")
    
    return _SYSTEM_PROMPT, _USER_PROMPT

def analyze_user_input(query: str, openai_api_key: str = None) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ëª¨ë“  ì •ë³´ë¥¼ í•œ ë²ˆì— ì¶”ì¶œ
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        openai_api_key: OpenAI API í‚¤
    
    Returns:
        {
            'is_simple_greeting': bool,
            'is_department_intro': bool,
            'department': str or None,
            'user_info': {'department': str, 'position': str, 'name': str} or None
        }
    """
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {
                'is_simple_greeting': True,
                'is_department_intro': False,
                'department': None,
                'user_info': None
            }
        
        client = openai.OpenAI(api_key=api_key)
        
        # ì¢…í•© ë¶„ì„ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ëª¨ë‘ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ê°„ë‹¨í•œ ì¸ì‚¬ë§/ëŒ€í™”ì¸ì§€ íŒë‹¨:
- ê°„ë‹¨í•œ ì¸ì‚¬ë§: "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•", "Hi", "ì¢‹ì€ ì•„ì¹¨", "ê°ì‚¬í•©ë‹ˆë‹¤" ë“±
- ìê¸°ì†Œê°œ í¬í•¨ ì¸ì‚¬ë§: "ì•ˆë…•, ë‚˜ëŠ” ê¹€ì² ìˆ˜ì•¼", "ê°œë°œíŒ€ì—ì„œ ì¼í•´ìš”, ì•ˆë…•" ë“±

2. ë¶€ì„œ/íŒ€ ì†Œê°œì¸ì§€ íŒë‹¨:
- "ë‚˜ëŠ” ê°œë°œíŒ€ì´ì•¼", "ê°œë°œíŒ€ì—ì„œ ì¼í•´ìš”", "ê°œë°œíŒ€ ê¹€â—‹â—‹ì…ë‹ˆë‹¤"
- "ì¸ì‚¬íŒ€ì—ì„œ ì¼í•´ìš”", "ITíŒ€ì…ë‹ˆë‹¤", "ê°œë°œë¶€ì„œì—ì„œ ê·¼ë¬´í•©ë‹ˆë‹¤" ë“±
- "ê°œë°œíŒ€ ì—…ë¬´ ì•Œë ¤ì¤˜", "ê°œë°œíŒ€ì—ì„œ ë­˜ í•´ì•¼í•´?", "ê°œë°œíŒ€ ì—…ë¬´ê°€ ê¶ê¸ˆí•´" ë“±
- "ìš°ë¦¬ë¶€ì„œì— ë„ì›€ì´ ë˜ë ¤ë©´", "ìš°ë¦¬íŒ€ì—ì„œ í•„ìš”í•œ ê²ƒ", "ìš°ë¦¬ ì¡°ì§ì— í•„ìš”í•œ ìŠ¤í‚¬" ë“±
- ë¶€ì„œëª… + ì—…ë¬´/ì¼/í•´ì•¼í•  ê²ƒ ë“±ì˜ ì¡°í•©ë„ ë¶€ì„œ ì†Œê°œë¡œ ì¸ì‹

3. ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ:
- ë¶€ì„œ/íŒ€: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ëª¨ë“  ë¶€ì„œ/íŒ€ëª… (ì˜ˆ: ê°œë°œíŒ€, ì¸ì‚¬íŒ€, íšŒê³„íŒ€, ì „ì‚°íŒ€, ITíŒ€, ê¸°íšíŒ€, ë§ˆì¼€íŒ…íŒ€, ê°œë°œë¶€ì„œ, ê¸°ìˆ íŒ€, ì†Œí”„íŠ¸ì›¨ì–´íŒ€, ì—°êµ¬íŒ€, ìš´ì˜íŒ€, ë³´ì•ˆíŒ€, í’ˆì§ˆíŒ€, ì˜ì—…íŒ€, ê³ ê°ì§€ì›íŒ€ ë“±)
- ì§ê¸‰: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ëª¨ë“  ì§ê¸‰ (ì˜ˆ: ì‚¬ì›, ëŒ€ë¦¬, ê³¼ì¥, ì°¨ì¥, ë¶€ì¥, ì´ì‚¬, ìƒë¬´, ì „ë¬´, ì‚¬ì¥, íŒ€ì¥, ë¶€ì„œì¥, ë³¸ë¶€ì¥, ëŒ€í‘œì´ì‚¬ ë“±)
- ì´ë¦„: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì„±ëª… (í•œê¸€, ì˜ë¬¸ ëª¨ë‘ ê°€ëŠ¥)

ì¤‘ìš”: 
- "ê°œë°œíŒ€ ì—…ë¬´ ì•Œë ¤ì¤˜" ê°™ì€ ì§ˆë¬¸ì—ì„œ "ê°œë°œíŒ€"ì„ ë¶€ì„œë¡œ ì¸ì‹í•˜ê³ , is_department_introë¥¼ trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
- "ìš°ë¦¬ë¶€ì„œ", "ìš°ë¦¬íŒ€", "ìš°ë¦¬ ì¡°ì§" ê°™ì€ í‘œí˜„ë„ ë¶€ì„œ ì†Œê°œë¡œ ì¸ì‹í•˜ì„¸ìš”.
- ê¸°ì¡´ ëŒ€í™”ì—ì„œ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ë¶€ì„œ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹ (JSON):
{
  "is_simple_greeting": true/false,
  "is_department_intro": true/false,
  "department": "ë¶€ì„œëª… ë˜ëŠ” null",
  "user_info": {
    "department": "ë¶€ì„œëª… ë˜ëŠ” null",
    "position": "ì§ê¸‰ ë˜ëŠ” null",
    "name": "ì´ë¦„ ë˜ëŠ” null"
  }
}

ì˜ˆì‹œ:
- "ì•ˆë…•í•˜ì„¸ìš”" â†’ {"is_simple_greeting": true, "is_department_intro": false, "department": null, "user_info": null}
- "ì•ˆë…•, ë‚˜ëŠ” ê¹€ì² ìˆ˜ì•¼" â†’ {"is_simple_greeting": true, "is_department_intro": false, "department": null, "user_info": {"department": null, "position": null, "name": "ê¹€ì² ìˆ˜"}}
- "ê°œë°œíŒ€ì—ì„œ ì¼í•´ìš”" â†’ {"is_simple_greeting": true, "is_department_intro": true, "department": "ê°œë°œíŒ€", "user_info": {"department": "ê°œë°œíŒ€", "position": null, "name": null}}
- "ì•ˆë…•, ë‚˜ëŠ” ê¹€ì² ìˆ˜, ê°œë°œíŒ€ì´ì•¼" â†’ {"is_simple_greeting": true, "is_department_intro": true, "department": "ê°œë°œíŒ€", "user_info": {"department": "ê°œë°œíŒ€", "position": null, "name": "ê¹€ì² ìˆ˜"}}"""

        user_prompt = f"ë‹¤ìŒ ì…ë ¥ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”: '{query}'"
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.0,
            max_tokens=200
        )
        
        result = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        try:
            analysis = json.loads(result)
            # ë¹ˆ ë¬¸ìì—´ì„ Noneìœ¼ë¡œ ë³€í™˜
            if analysis.get('user_info'):
                for key in analysis['user_info']:
                    if analysis['user_info'][key] == "" or analysis['user_info'][key] == "null":
                        analysis['user_info'][key] = None
            return analysis
        except json.JSONDecodeError:
            return {
                'is_simple_greeting': True,
                'is_department_intro': False,
                'department': None,
                'user_info': None
            }
        
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            'is_simple_greeting': True,
            'is_department_intro': False,
            'department': None,
            'user_info': None
        }

def is_simple_greeting(query: str, openai_api_key: str = None) -> bool:
    """
    í†µí•©ëœ ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì¸ì‚¬ë§ì¸ì§€ íŒë‹¨
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        openai_api_key: OpenAI API í‚¤
    
    Returns:
        True if simple greeting, False if complex question
    """
    analysis = analyze_user_input(query, openai_api_key)
    return analysis.get('is_simple_greeting', True)

def update_user_context(conversation_history: List[Dict], user_info: Dict[str, str]) -> List[Dict]:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì‚¬ìš©ì ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸
    
    Args:
        conversation_history: ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬
        user_info: ì¶”ì¶œëœ ì‚¬ìš©ì ì •ë³´
    
    Returns:
        ì—…ë°ì´íŠ¸ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬
    """
    if not conversation_history:
        conversation_history = []
    
    # ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ì°¾ê¸°
    user_context = None
    for msg in conversation_history:
        if isinstance(msg, dict) and msg.get("role") == "system" and "user_context" in msg.get("content", ""):
            user_context = msg
            break
    
    # ìƒˆë¡œìš´ ì‚¬ìš©ì ì •ë³´ ìƒì„±
    context_content = f"user_context: {user_info}"
    
    if user_context:
        # ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ì—…ë°ì´íŠ¸
        user_context["content"] = context_content
    else:
        # ìƒˆë¡œìš´ ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
        conversation_history.insert(0, {
            "role": "system",
            "content": context_content
        })
    
    return conversation_history

def prioritize_results_by_department(search_results: List[Dict], user_department: str, openai_api_key: str = None) -> List[Dict]:
    """
    ì‚¬ìš©ì ë¶€ì„œì— ë§ê²Œ ê²€ìƒ‰ ê²°ê³¼ ìš°ì„ ìˆœìœ„ ì¡°ì • (LLM ê¸°ë°˜ ë™ì  ì²˜ë¦¬)
    
    Args:
        search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        user_department: ì‚¬ìš©ì ë¶€ì„œ
        openai_api_key: OpenAI API í‚¤
    
    Returns:
        ìš°ì„ ìˆœìœ„ê°€ ì¡°ì •ëœ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    if not user_department or not search_results:
        return search_results
    
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶€ì„œë³„ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ë™ì  ì¶”ì¶œ
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if api_key:
            client = openai.OpenAI(api_key=api_key)
            
            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ
            categories = list(set([result.get('category', '') for result in search_results if result.get('category')]))
            
            system_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì¸í„°ë„·ì§„í¥ì›(KISA)ì˜ ì—…ë¬´ ê°€ì´ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ "{user_department}"ì—ì„œ ê·¼ë¬´í•  ë•Œ, ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì¹´í…Œê³ ë¦¬ë“¤ì„ ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.

ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:
{', '.join(categories)}

ë‹µë³€ í˜•ì‹: ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì¹´í…Œê³ ë¦¬ëª…ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì„¸ìš”.
ì˜ˆì‹œ: "ì¸ì‚¬ ê·œì •, ë³µë¦¬í›„ìƒ ê·œì •, ì¸ì‚¬íŒ€ ì—…ë¬´ ê°€ì´ë“œ"

{user_department}ì™€ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ìƒìœ„ 3-5ê°œ ì¹´í…Œê³ ë¦¬ë§Œ ì„ íƒí•˜ì„¸ìš”."""

            user_prompt = f"{user_department}ì—ì„œ ê·¼ë¬´í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
            
            response_result = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=100
            )
            
            priority_categories_text = response_result.choices[0].message.content.strip()
            priority_categories = [cat.strip() for cat in priority_categories_text.split(',')]
            
        else:
            # API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ìš°ì„ ìˆœìœ„ ì‚¬ìš©
            priority_categories = []
    
    except Exception as e:
        logger.error(f"ë¶€ì„œë³„ ìš°ì„ ìˆœìœ„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        priority_categories = []
    
    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê²°ê³¼ ë¶„ë¥˜
    high_priority = []
    medium_priority = []
    low_priority = []
    
    for result in search_results:
        category = result.get('category', '')
        is_high_priority = any(priority in category for priority in priority_categories)
        
        if is_high_priority:
            high_priority.append(result)
        elif category:
            medium_priority.append(result)
        else:
            low_priority.append(result)
    
    # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì¬ì •ë ¬
    prioritized_results = high_priority + medium_priority + low_priority
    
    logger.info(f"ë¶€ì„œë³„ ìš°ì„ ìˆœìœ„ ì¡°ì •: {user_department} - ê³ ìš°ì„ ìˆœìœ„: {len(high_priority)}, ì¤‘ìš°ì„ ìˆœìœ„: {len(medium_priority)}, ì €ìš°ì„ ìˆœìœ„: {len(low_priority)}")
    
    return prioritized_results

def analyze_question_level(query: str, openai_api_key: str = None) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ì˜ ìˆ˜ì¤€ê³¼ ì˜ˆìƒ í›„ì† ì§ˆë¬¸ì„ ë¶„ì„
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        openai_api_key: OpenAI API í‚¤
    
    Returns:
        {'level': 'ê¸°ì´ˆ/ì¤‘ê¸‰/ê³ ê¸‰', 'follow_up_questions': ['ì§ˆë¬¸1', 'ì§ˆë¬¸2', ...]}
    """
    try:
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {'level': 'ì¤‘ê¸‰', 'follow_up_questions': []}
        
        client = openai.OpenAI(api_key=api_key)
        
        system_prompt = """ë‹¹ì‹ ì€ ì§ˆë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒë‹¨í•˜ì„¸ìš”:

1. ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ë¥˜:
- ê¸°ì´ˆ: ê¸°ë³¸ì ì¸ ê°œë…ì´ë‚˜ ì ˆì°¨ì— ëŒ€í•œ ì§ˆë¬¸ (ì˜ˆ: "íœ´ê°€ ì‹ ì²­ì´ ë­ì•¼?", "ê¸‰ì—¬ëŠ” ì–¸ì œ ë°›ë‚˜ìš”?")
- ì¤‘ê¸‰: êµ¬ì²´ì ì¸ ì—…ë¬´ ì ˆì°¨ë‚˜ ì •ì±…ì— ëŒ€í•œ ì§ˆë¬¸ (ì˜ˆ: "íœ´ê°€ ì‹ ì²­ ì ˆì°¨ëŠ”?", "ì—°ì°¨ ì‚¬ìš© ê·œì •ì€?")
- ê³ ê¸‰: ë³µì¡í•œ ì—…ë¬´ë‚˜ ì •ì±… í•´ì„ì— ëŒ€í•œ ì§ˆë¬¸ (ì˜ˆ: "íŠ¹ë³„íœ´ê°€ì™€ ì—°ì°¨ì˜ ì°¨ì´ì ì€?", "ê¸‰ì—¬ ê³„ì‚° ë°©ì‹ì€?")

2. ì˜ˆìƒ í›„ì† ì§ˆë¬¸ ìƒì„±:
ì§ˆë¬¸ ìˆ˜ì¤€ì— ë”°ë¼ ì‚¬ìš©ìê°€ ë‹¤ìŒì— ê¶ê¸ˆí•´í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ìœ ë„í˜• ì§ˆë¬¸ìœ¼ë¡œ 2-3ê°œ ìƒì„±í•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹ (JSON):
{
  "level": "ê¸°ì´ˆ/ì¤‘ê¸‰/ê³ ê¸‰",
  "follow_up_questions": ["í˜¹ì‹œ ~ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", "~ì— ëŒ€í•œ ì •ë³´ë„ í•„ìš”í•˜ì‹¤ê¹Œìš”?", "~ì— ëŒ€í•´ì„œë„ ì•Œê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."]
}"""

        user_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: '{query}'"
        
        response_result = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        
        result = response_result.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        import json
        try:
            analysis = json.loads(result)
            return analysis
        except json.JSONDecodeError:
            return {'level': 'ì¤‘ê¸‰', 'follow_up_questions': []}
        
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {'level': 'ì¤‘ê¸‰', 'follow_up_questions': []}

def _enhance_answer_with_follow_ups(original_answer: str, follow_up_questions: List[str], 
                                   search_results: List[Dict], user_info: Dict[str, str], 
                                   openai_api_key: str = None) -> str:
    """
    ê¸°ì´ˆ ì§ˆë¬¸ì— ëŒ€í•´ ì˜ˆìƒ í›„ì† ì§ˆë¬¸ë“¤ì„ ë¯¸ë¦¬ ë‹µë³€í•˜ì—¬ ë‹µë³€ì„ ë³´ê°•
    
    Args:
        original_answer: ì›ë³¸ ë‹µë³€
        follow_up_questions: ì˜ˆìƒ í›„ì† ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        search_results: ê²€ìƒ‰ ê²°ê³¼
        user_info: ì‚¬ìš©ì ì •ë³´
        openai_api_key: OpenAI API í‚¤
    
    Returns:
        ë³´ê°•ëœ ë‹µë³€
    """
    try:
        api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not api_key or not follow_up_questions:
            return original_answer
        
        client = openai.OpenAI(api_key=api_key)
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        context_text = ""
        for i, result in enumerate(search_results[:3], 1):
            text = result.get('text', '')
            if len(text) > 300:
                text = text[:300] + "..."
            context_text += f"[{i}] {text}\n\n"
        
        # ì‚¬ìš©ì ì •ë³´ ë°˜ì˜
        user_context = ""
        if user_info.get('department'):
            user_context += f"ì‚¬ìš©ì ë¶€ì„œ: {user_info['department']}\n"
        if user_info.get('position'):
            user_context += f"ì‚¬ìš©ì ì§ê¸‰: {user_info['position']}\n"
        
        system_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì¸í„°ë„·ì§„í¥ì›(KISA)ì˜ ì—…ë¬´ ê°€ì´ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ê¸°ì´ˆì ì¸ ì§ˆë¬¸ì„ í–ˆì„ ë•Œ, ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì œê³µí•˜ê³  ìœ ë„í˜• ì§ˆë¬¸ìœ¼ë¡œ ë” ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.

ì‚¬ìš©ì ì •ë³´:
{user_context}

ì°¸ê³  ì»¨í…ìŠ¤íŠ¸:
{context_text}

ë‹µë³€ í˜•ì‹:
1. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì œê³µ
2. ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë‚˜ íŒì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
3. ìœ ë„í˜• ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ìš©ìì˜ ê´€ì‹¬ì„ ëŒì–´ ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„
4. ì „ì²´ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ì •ë³´ ì œê³µ

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì‚¬ìš©ì ë¶€ì„œì™€ ì§ê¸‰ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ ì–´ì¡°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
"ì›ë³¸ ë‹µë³€", "ì¶”ê°€ë¡œ ê¶ê¸ˆí•  ìˆ˜ ìˆëŠ” ë‚´ìš©" ê°™ì€ í‚¤ì›Œë“œëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”."""

        user_prompt = f"""í˜„ì¬ ë‹µë³€: {original_answer}

ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ê¶ê¸ˆí•´í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ë“¤:
{chr(10).join([f"- {q}" for q in follow_up_questions])}

ìœ„ ë‚´ìš©ë“¤ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì—¬ ë” ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ìœ¼ë¡œ ë³´ê°•í•´ì£¼ì„¸ìš”.
ìœ ë„í˜• ì§ˆë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ì§ˆë¬¸í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ì„¸ìš”."""

        response_result = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5,
            max_tokens=800
        )
        
        enhanced_answer = response_result.choices[0].message.content.strip()
        return enhanced_answer
        
    except Exception as e:
        logger.error(f"í›„ì† ì§ˆë¬¸ ë‹µë³€ ë³´ê°• ì‹¤íŒ¨: {e}")
        return original_answer

def get_user_context(conversation_history: List[Dict]) -> Dict[str, str]:
    """
    ëŒ€í™” íˆìŠ¤í† ë¦¬ì—ì„œ ì‚¬ìš©ì ì •ë³´ ì¶”ì¶œ
    
    Args:
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
    
    Returns:
        ì‚¬ìš©ì ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    if not conversation_history:
        return {}
    
    for msg in conversation_history:
        if isinstance(msg, dict) and msg.get("role") == "system":
            content = msg.get("content", "")
            if "user_context:" in content:
                try:
                    import json
                    context_str = content.split("user_context:")[1].strip()
                    return json.loads(context_str)
                except:
                    return {}
    
    return {}

def answer_query(query: str, openai_api_key: str = None, explicit_domain: str = None, conversation_history: List[Dict] = None) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ì— ëŒ€í•œ ì™„ì „í•œ RAG ë‹µë³€ ìƒì„± (ë©€í‹°í„´ ëŒ€í™” ì§€ì›)
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        openai_api_key: OpenAI API í‚¤ (ì„ íƒì‚¬í•­)
        explicit_domain: ëª…ì‹œì  ë„ë©”ì¸ (ì„ íƒì‚¬í•­)
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
    
    Returns:
        ë‹µë³€, ë©”íƒ€ë°ì´í„°, ì°¸ê³ ë¬¸ì„œë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    start_time = time.time()
    
    try:
        logger.info(f"RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘ - ì§ˆë¬¸: {query}")
        print(f"DEBUG: RAG íŒŒì´í”„ë¼ì¸ ì‹œì‘ - ì§ˆë¬¸: {query}")
        
        # ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ì¢…í•© ë¶„ì„ (í•œ ë²ˆì˜ LLM í˜¸ì¶œë¡œ ëª¨ë“  ì •ë³´ ì¶”ì¶œ)
        input_analysis = analyze_user_input(query, openai_api_key)
        logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ë¶„ì„: {input_analysis}")
        print(f"DEBUG: ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ë¶„ì„: {input_analysis}")
        
        # ì‚¬ìš©ì ì •ë³´ê°€ ìˆìœ¼ë©´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
        user_info = input_analysis.get('user_info')
        if user_info and any(user_info.values()):
            conversation_history = update_user_context(conversation_history, user_info)
            logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì €ì¥ë¨: {user_info}")
            print(f"DEBUG: ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì €ì¥ë¨: {user_info}")
        
        # ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        existing_user_info = get_user_context(conversation_history)
        logger.info(f"ğŸ‘¤ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´: {existing_user_info}")
        print(f"DEBUG: ğŸ‘¤ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´: {existing_user_info}")
        
        # ğŸ¢ ë¶€ì„œ ì†Œê°œ ì§ˆë¬¸ ì²˜ë¦¬ (ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ ê³ ë ¤)
        is_department_intro = input_analysis.get('is_department_intro', False)
        department = input_analysis.get('department')
        
        # ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ì—ì„œ ë¶€ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        existing_department = existing_user_info.get('department')
        
        # ë¶€ì„œ ì†Œê°œ ì§ˆë¬¸ì´ê±°ë‚˜ "ìš°ë¦¬ë¶€ì„œ" ê°™ì€ í‘œí˜„ì´ ìˆëŠ” ê²½ìš°
        if (is_department_intro and department) or ('ìš°ë¦¬ë¶€ì„œ' in query or 'ìš°ë¦¬íŒ€' in query or 'ìš°ë¦¬ ì¡°ì§' in query):
            # í˜„ì¬ ì§ˆë¬¸ì—ì„œ ë¶€ì„œë¥¼ ì°¾ì§€ ëª»í–ˆì§€ë§Œ ê¸°ì¡´ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
            if not department and existing_department:
                department = existing_department
                is_department_intro = True
                logger.info(f"ğŸ¢ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ì—ì„œ ë¶€ì„œ ì¶”ì¶œ: {department}")
                print(f"DEBUG: ğŸ¢ ê¸°ì¡´ ì‚¬ìš©ì ì •ë³´ì—ì„œ ë¶€ì„œ ì¶”ì¶œ: {department}")
        
        # ë©€í‹°í„´ ëŒ€í™”ì—ì„œ "ë‚´ê°€ í•´ì•¼ í•  ì¼" ê°™ì€ ì§ˆë¬¸ ì²˜ë¦¬
        if not is_department_intro and not department and existing_department:
            # ê¸°ì¡´ ëŒ€í™”ì—ì„œ ë¶€ì„œ ì •ë³´ê°€ ìˆê³ , í˜„ì¬ ì§ˆë¬¸ì´ ì—…ë¬´ ê´€ë ¨ì´ë©´ ë¶€ì„œ ì†Œê°œë¡œ ì²˜ë¦¬
            work_related_keywords = ['í•´ì•¼í• ', 'í•´ì•¼ í• ', 'ì—…ë¬´', 'ì¼', 'ë­˜', 'ë¬´ìŠ¨', 'ì–´ë–¤', 'í•´ì•¼ë¼', 'í•´ì•¼ ë¼']
            if any(keyword in query for keyword in work_related_keywords):
                department = existing_department
                is_department_intro = True
                logger.info(f"ğŸ¢ ë©€í‹°í„´ ëŒ€í™”ì—ì„œ ë¶€ì„œ ì •ë³´ í™œìš©: {department}")
                print(f"DEBUG: ğŸ¢ ë©€í‹°í„´ ëŒ€í™”ì—ì„œ ë¶€ì„œ ì •ë³´ í™œìš©: {department}")
        
        if is_department_intro and department:
            logger.info(f"ğŸ¢ ë¶€ì„œ ì†Œê°œ ì§ˆë¬¸ ê°ì§€: {department}")
            print(f"DEBUG: ğŸ¢ ë¶€ì„œ ì†Œê°œ ì§ˆë¬¸ ê°ì§€: {department}")
            
            # ë¶€ì„œë³„ ì—…ë¬´ ì†Œê°œë¥¼ ìœ„í•œ ë™ì  ì‘ë‹µ ìƒì„±
            try:
                api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
                if api_key:
                    client = openai.OpenAI(api_key=api_key)
                    
                    # LLMì´ ë™ì ìœ¼ë¡œ ì§ˆë¬¸ ìœ í˜•ì„ íŒë‹¨í•˜ê³  ì‘ë‹µ ìƒì„±
                    system_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì¸í„°ë„·ì§„í¥ì›(KISA)ì˜ ì—…ë¬´ ê°€ì´ë“œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ "{department}"ì— ë§ëŠ” ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ ë° ì‘ë‹µ ê°€ì´ë“œ:
1. ì§ˆë¬¸ ìœ í˜• íŒŒì•…:
   - ì—…ë¬´ ê´€ë ¨: "ì—…ë¬´ ì•Œë ¤ì¤˜", "ë­˜ í•´ì•¼í•´", "ì—…ë¬´ê°€ ê¶ê¸ˆí•´"
   - í•™ìŠµ ê´€ë ¨: "ê³µë¶€", "í•™ìŠµ", "ë°°ìš°", "ìŠ¤í‚¬", "ìê²©ì¦"
   - ë„êµ¬/ê¸°ìˆ  ê´€ë ¨: "ë„êµ¬", "ê¸°ìˆ ", "í”„ë¡œê·¸ë¨", "ì‹œìŠ¤í…œ"
   - ê¸°íƒ€: ì¡°ì§ë¬¸í™”, ì»¤ë¦¬ì–´, ì„±ì¥ ë“±

2. ë‹µë³€ êµ¬ì„±:
   - ì§ˆë¬¸ ìœ í˜•ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
   - í•´ë‹¹ ë¶€ì„œì˜ íŠ¹ì„±ê³¼ ì—…ë¬´ í™˜ê²½ ê³ ë ¤
   - ì‹¤ë¬´ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥í•œ ì¡°ì–¸ í¬í•¨
   - ì¶”ê°€ í•™ìŠµì´ë‚˜ ë°œì „ ë°©í–¥ ì œì‹œ

3. ë‹µë³€ ìŠ¤íƒ€ì¼:
   - ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°
   - êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ì„¤ëª… í¬í•¨
   - ë‹¨ê³„ë³„ ê°€ì´ë“œë‚˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì œê³µ
   - ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ëŠ” ë§ˆë¬´ë¦¬

í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
                    
                    # LLMì´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë‹µë³€ ìƒì„±
                    user_prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: "{query}"
ì‚¬ìš©ì ë¶€ì„œ: "{department}"

ìœ„ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ {department}ì— ë§ëŠ” ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì§ˆë¬¸ì˜ ì˜ë„ì™€ ë§¥ë½ì„ íŒŒì•…í•˜ê³ , ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""
                    
                    response_result = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=500
                    )
                    
                    department_response = response_result.choices[0].message.content.strip()
                    
                    return {
                        'answer': department_response,
                        'metadata': {
                            'processing_time': time.time() - start_time,
                            'query_type': 'department_intro',
                            'department': department,
                            'user_info': user_info
                        },
                        'references': []
                    }
            except Exception as e:
                logger.error(f"ë¶€ì„œ ì†Œê°œ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ğŸš€ ê°„ë‹¨í•œ ì§ˆë¬¸ ê°ì§€ (ì´ë¯¸ ë¶„ì„ëœ ê²°ê³¼ ì‚¬ìš©)
        is_simple_query = input_analysis.get('is_simple_greeting', True)
        
        if conversation_history and len(conversation_history) > 0:
            logger.info(f"ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°ì§€ ({len(conversation_history)}ê°œ ë©”ì‹œì§€), ë©€í‹°í„´ ëŒ€í™”ë¡œ ì²˜ë¦¬")
            print(f"DEBUG: ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°ì§€, ë©€í‹°í„´ ëŒ€í™”ë¡œ ì²˜ë¦¬")
            if not is_simple_query:
                logger.info("ë³µì¡í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
                print(f"DEBUG: ë³µì¡í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        
        if is_simple_query:
            logger.info(f"âš¡ ê°„ë‹¨í•œ ì§ˆë¬¸ ê°ì§€, LLMìœ¼ë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±: {query}")
            print(f"DEBUG: âš¡ ê°„ë‹¨í•œ ì§ˆë¬¸ ê°ì§€, LLMìœ¼ë¡œ ì§ì ‘ ì‘ë‹µ ìƒì„±")
            
            # LLMì—ê²Œ ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± ìš”ì²­
            try:
                api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
                if not api_key:
                    # API í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
                    response = "ì•ˆë…•í•˜ì„¸ìš”! ì—…ë¬´ ê´€ë ¨ ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
                else:
                    client = openai.OpenAI(api_key=api_key)
                    
                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ê³ ë ¤í•œ ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
                    messages = []
                    
                    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                    system_prompt = """ë‹¹ì‹ ì€ í•œêµ­ì¸í„°ë„·ì§„í¥ì›(KISA)ì˜ ì—…ë¬´ ê°€ì´ë“œ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°„ë‹¨í•œ ì¸ì‚¬ë§ì´ë‚˜ ì§§ì€ ëŒ€í™”ì— ì¹œê·¼í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
ìê¸°ì†Œê°œê°€ í¬í•¨ëœ ê²½ìš° í•´ë‹¹ ì •ë³´ë¥¼ ì¸ì •í•˜ê³  ë°˜ì‘í•˜ì„¸ìš”.
ì—…ë¬´ ê´€ë ¨ ë„ì›€ì„ ì œê³µí•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŒì„ ì•Œë ¤ì£¼ì„¸ìš”.
2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""
                    
                    messages.append({"role": "system", "content": system_prompt})
                    
                    # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                    if conversation_history and len(conversation_history) > 0:
                        for msg in conversation_history:
                            if isinstance(msg, dict) and "role" in msg and "content" in msg:
                                role = msg.get("role", "user")
                                if role in ["user", "assistant"]:
                                    content = str(msg.get("content", ""))[:1000]  # ê¸¸ì´ ì œí•œ
                                    if content.strip():
                                        messages.append({"role": role, "content": content})
                    
                    # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
                    messages.append({"role": "user", "content": query})
                    
                    response_result = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages,
                        temperature=0.7,
                        max_tokens=150
                    )
                    
                    response = response_result.choices[0].message.content.strip()
                    
            except Exception as e:
                logger.error(f"ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ ì‚¬ìš©
                response = "ì•ˆë…•í•˜ì„¸ìš”! ì—…ë¬´ ê´€ë ¨ ê¶ê¸ˆí•œ ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
            
            total_time = time.time() - start_time
            logger.info(f"âš¡ ê°„ë‹¨í•œ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ (ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ)")
            
            return {
                'answer': response,
                'contexts': [],
                'sources': [],
                'keywords': [],
                'domains': [],
                'search_strategy': 'simple_response',
                'total_time': total_time,
                'search_time': 0,
                'answer_time': total_time
            }
        
        # ğŸ”¥ ë³µì¡í•œ ì§ˆë¬¸ ì²˜ë¦¬ (í†µí•©ëœ system_promptê°€ ë³´ì•ˆ ê²€ì¦ í¬í•¨)
        logger.info("ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€, ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        print(f"DEBUG: ë³µì¡í•œ ì§ˆë¬¸ ê°ì§€, ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        
        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ
        logger.info("1ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘")
        keywords_start = time.time()
        try:
            keywords = extract_keywords(query, openai_api_key)
            logger.info(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - keywords_start:.2f}ì´ˆ)")
            print(f"DEBUG: ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            keywords = []
            print(f"WARNING: í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©: {e}")
        
        # 2ë‹¨ê³„: ë„ë©”ì¸ ì¶”ì •
        logger.info("2ë‹¨ê³„: ë„ë©”ì¸ ì¶”ì • ì‹œì‘")
        domain_start = time.time()
        try:
            if explicit_domain:
                # ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ë„ë©”ì¸ ìš°ì„ 
                estimated_domains = [explicit_domain]
                logger.info(f"ëª…ì‹œì  ë„ë©”ì¸ ì‚¬ìš©: {explicit_domain}")
                print(f"DEBUG: ëª…ì‹œì  ë„ë©”ì¸ ì‚¬ìš©: {explicit_domain}")
            else:
                # í‚¤ì›Œë“œ ê¸°ë°˜ ë„ë©”ì¸ ì¶”ì •
                estimated_domains = guess_domains_from_keywords(keywords)
                logger.info(f"ë„ë©”ì¸ ì¶”ì • ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - domain_start:.2f}ì´ˆ)")
                print(f"DEBUG: ì¶”ì •ëœ ë„ë©”ì¸: {estimated_domains}")
        except Exception as e:
            logger.error(f"ë„ë©”ì¸ ì¶”ì • ì‹¤íŒ¨: {e}")
            estimated_domains = []
            print(f"WARNING: ë„ë©”ì¸ ì¶”ì • ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©: {e}")
        
        # 3ë‹¨ê³„: í–¥ìƒëœ RAG ê²€ìƒ‰ (ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° êµ¬ì¡° í™œìš©)
        logger.info("3ë‹¨ê³„: RAG ê²€ìƒ‰ ì‹œì‘")
        search_start = time.time()
        
        try:
            # ê²€ìƒ‰ ì „ëµ ê²°ì •
            search_strategy = _determine_search_strategy(query, keywords, estimated_domains)
            logger.info(f"ê²€ìƒ‰ ì „ëµ ê²°ì •: {search_strategy}")
            print(f"DEBUG: ê²€ìƒ‰ ì „ëµ: {search_strategy}")
            
            # ì „ëµì— ë”°ë¥¸ ê²€ìƒ‰ ì‹¤í–‰
            if search_strategy['type'] == 'form_specific':
                # ì„œì‹ ì „ìš© ê²€ìƒ‰
                searcher = RagSearcher()
                search_results = searcher.search_forms(query=query, top_k=10)
                logger.info(f"ì„œì‹ ì „ìš© ê²€ìƒ‰ ì‹¤í–‰ - ê²°ê³¼ ìˆ˜: {len(search_results)}")
                print(f"DEBUG: ì„œì‹ ì „ìš© ê²€ìƒ‰ ì‹¤í–‰ - ê²°ê³¼ ìˆ˜: {len(search_results)}")
            elif search_strategy['type'] == 'domain_specific':
                search_results = RagSearcher().search_by_domain(
                    query=query, 
                    domain=search_strategy['domain'], 
                    top_k=10
                )
            elif search_strategy['type'] == 'file_type_specific':
                search_results = RagSearcher().search_by_file_type(
                    query=query, 
                    file_type=search_strategy['file_type'], 
                    top_k=10
                )
            elif search_strategy['type'] == 'recency_aware':
                search_results = RagSearcher().search_by_recency(
                    query=query, 
                    min_recency=search_strategy['min_recency'], 
                    top_k=10
                )
            else:
                # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ê¸°ë³¸)
                searcher = RagSearcher()
                search_results = searcher.hybrid_search(
                    query=query,
                    domain_list=estimated_domains if estimated_domains else None,
                    file_types=search_strategy.get('file_types'),
                    min_recency=search_strategy.get('min_recency'),
                    top_k=10
                )
            
            # ì‚¬ìš©ì ë¶€ì„œì— ë§ê²Œ ê²€ìƒ‰ ê²°ê³¼ ìš°ì„ ìˆœìœ„ ì¡°ì •
            user_department = existing_user_info.get('department', '')
            if user_department:
                search_results = prioritize_results_by_department(search_results, user_department, openai_api_key)
                logger.info(f"ë¶€ì„œë³„ ìš°ì„ ìˆœìœ„ ì¡°ì • ì ìš©: {user_department}")
                print(f"DEBUG: ë¶€ì„œë³„ ìš°ì„ ìˆœìœ„ ì¡°ì • ì ìš©: {user_department}")
            
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - search_start:.2f}ì´ˆ, ê²°ê³¼ ìˆ˜: {len(search_results)})")
            print(f"DEBUG: ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(search_results)}")
            
        except Exception as e:
            logger.error(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            search_results = []
            print(f"ERROR: RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # 4ë‹¨ê³„: ë‹µë³€ ìƒì„±
        logger.info("4ë‹¨ê³„: ë‹µë³€ ìƒì„± ì‹œì‘")
        answer_start = time.time()
        
        try:
            if search_results:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš° ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
                if len(search_results) < 3:
                    result = {
                        'success': True,
                        'answer': "ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” ëª…í™•í•˜ê²Œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•©ë‹ˆë‹¤.",
                        'used_domains': estimated_domains,
                        'search_strategy': search_strategy,
                        'top_docs': [],
                        'sources': []
                    }
                    logger.info("ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±ìœ¼ë¡œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜")
                    return result
                
                # ì„œì‹ ê²€ìƒ‰ ê²°ê³¼ì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                if search_strategy['type'] == 'form_specific':
                    answer = _generate_form_response(query, search_results[:5])
                else:
                    # ì¼ë°˜ ë‹µë³€ ìƒì„±
                    contexts = [result['text'] for result in search_results[:5]]
                    
                    # ì‹œìŠ¤í…œ ë° ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                    system_prompt, user_prompt = _init_prompts()
                    
                    # ë‹µë³€ ìƒì„± (ì˜¬ë°”ë¥¸ ì¸ìë¡œ í˜¸ì¶œ)
                    answer = make_answer(
                        query=query,
                        contexts=search_results[:5],  # ì „ì²´ ê²°ê³¼ ê°ì²´ ì „ë‹¬
                        api_key=None,  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
                        conversation_history=conversation_history, # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
                        user_info=existing_user_info  # ì‚¬ìš©ì ì •ë³´ ì „ë‹¬
                    )
                
                # ë‹µë³€ í’ˆì§ˆ ê²€ì¦
                if not validate_answer_quality(answer, query):
                    logger.warning("ë‹µë³€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    print("WARNING: ë‹µë³€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                    answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê±°ë‚˜, ê´€ë ¨ ë„ë©”ì¸ì„ ëª…ì‹œí•´ ì£¼ì„¸ìš”."
                
                # ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„ ë° ì˜ˆìƒ í›„ì† ì§ˆë¬¸ ë¯¸ë¦¬ ë‹µë³€
                try:
                    question_analysis = analyze_question_level(query, openai_api_key)
                    question_level = question_analysis.get('level', 'ì¤‘ê¸‰')
                    follow_up_questions = question_analysis.get('follow_up_questions', [])
                    
                    logger.info(f"ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„: {question_level}, ì˜ˆìƒ í›„ì† ì§ˆë¬¸: {len(follow_up_questions)}ê°œ")
                    print(f"DEBUG: ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„: {question_level}, ì˜ˆìƒ í›„ì† ì§ˆë¬¸: {len(follow_up_questions)}ê°œ")
                    
                    # ê¸°ì´ˆ ìˆ˜ì¤€ ì§ˆë¬¸ì˜ ê²½ìš° ì˜ˆìƒ í›„ì† ì§ˆë¬¸ë“¤ì„ ë¯¸ë¦¬ ë‹µë³€
                    if question_level == 'ê¸°ì´ˆ' and follow_up_questions:
                        enhanced_answer = _enhance_answer_with_follow_ups(
                            answer, follow_up_questions, search_results[:3], 
                            existing_user_info, openai_api_key
                        )
                        if enhanced_answer:
                            answer = enhanced_answer
                            logger.info("ê¸°ì´ˆ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ˆìƒ í›„ì† ì§ˆë¬¸ ë‹µë³€ ì¶”ê°€")
                            print("DEBUG: ê¸°ì´ˆ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ˆìƒ í›„ì† ì§ˆë¬¸ ë‹µë³€ ì¶”ê°€")
                    
                except Exception as e:
                    logger.error(f"ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„ ì‹¤íŒ¨: {e}")
                    print(f"WARNING: ì§ˆë¬¸ ìˆ˜ì¤€ ë¶„ì„ ì‹¤íŒ¨: {e}")
                
                # ì°¸ê³  ë¬¸ì„œ ì •ë³´ ìƒì„± (ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° í™œìš©)
                if search_strategy['type'] == 'form_specific':
                    # ì„œì‹ ê²€ìƒ‰ ê²°ê³¼ì˜ ê²½ìš° ì„œì‹ ì •ë³´ë¥¼ ì†ŒìŠ¤ë¡œ ì œê³µ
                    sources = _format_form_sources(search_results[:5])
                else:
                    sources = _format_sources_with_metadata(search_results[:5])
                
                result = {
                    'success': True,
                    'answer': answer,
                    'used_domains': estimated_domains,
                    'search_strategy': search_strategy,
                    'top_docs': search_results[:5],
                    'sources': sources
                }
                
                logger.info(f"ë‹µë³€ ìƒì„± ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - answer_start:.2f}ì´ˆ)")
                
            else:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                result = {
                    'success': True,
                    'answer': "ì§ˆë¬¸ì„ ì¡°ê¸ˆ ë” ëª…í™•í•˜ê²Œ í•´ì£¼ì‹œë©´ ê°ì‚¬í•©ë‹ˆë‹¤.",
                    'used_domains': estimated_domains,
                    'search_strategy': search_strategy,
                    'top_docs': [],
                    'sources': []
                }
                logger.info("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒìœ¼ë¡œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜")
            
            total_time = time.time() - start_time
            logger.info(f"RAG íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ)")
            
            return result
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ERROR: ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
        
    except Exception as e:
        total_time = time.time() - start_time
        logger.error(f"RAG íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ (ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ): {e}")
        print(f"RAG íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        return {
            'success': False,
            'error': str(e),
            'answer': "ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }

def _is_form_related_query(query: str, keywords: List[str]) -> bool:
    """
    ì„œì‹ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
    
    Returns:
        ì„œì‹ ê´€ë ¨ ì§ˆë¬¸ ì—¬ë¶€
    """
    query_lower = query.lower()
    
    # ì„œì‹ ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´
    form_keywords = [
        'ì„œì‹', 'ì–‘ì‹', 'ì‹ ì²­ì„œ', 'ì œì¶œì„œ', 'ì²­êµ¬ì„œ', 'ìš”ì²­ì„œ', 'ë³´ê³ ì„œ', 'í‰ê°€ì„œ',
        'í™•ì¸ì„œ', 'ì„œì•½ì„œ', 'ê³„ì•½ì„œ', 'ìŠ¹ì¸ì„œ', 'í†µì§€ì„œ', 'ë“±ë¡ì„œ', 'ë³€ê²½ì„œ',
        'ê´€ë¦¬ì„œ', 'ìš´ì˜ì„œ', 'ì²˜ë¦¬ì„œ', 'ëŒ€ì¥', 'ì ‘ìˆ˜ì¦', 'ì¼ì§€', 'ì²´í¬ë¦¬ìŠ¤íŠ¸',
        'ì ê²€í‘œ', 'ê²°ê³¼í‘œ', 'ê²€í† ì„œ', 'ì™„ë£Œí™•ì¸ì„œ', 'ì·¨ì†Œì‹ ì²­ì„œ', 'ì¬ë°œê¸‰ì‹ ì²­ì„œ',
        'ì¸ì¦ì—°ì¥ì‹ ì²­ì„œ', 'ìœ¤ë¦¬ì„œì•½ì„œ', 'ë³´ì•ˆì„œì•½ì„œ', 'ì§ë¬´ìœ¤ë¦¬ì„œì•½ì„œ'
    ]
    
    # ì§ˆë¬¸ì— ì„œì‹ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    for keyword in form_keywords:
        if keyword in query_lower:
            return True
    
    # í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì—ì„œë„ í™•ì¸
    for keyword in keywords:
        if any(form_kw in keyword.lower() for form_kw in form_keywords):
            return True
    
    # ì„œì‹ ìš”ì²­ íŒ¨í„´ í™•ì¸
    form_request_patterns = [
        'ì„œì‹ ì£¼ì„¸ìš”', 'ì–‘ì‹ ì£¼ì„¸ìš”', 'ì‹ ì²­ì„œ ì£¼ì„¸ìš”', 'ì–‘ì‹ ì°¾ì•„ì¤˜',
        'ì„œì‹ ì°¾ì•„ì¤˜', 'ì‹ ì²­ì„œ ì°¾ì•„ì¤˜', 'ì–‘ì‹ ë‹¤ìš´ë¡œë“œ', 'ì„œì‹ ë‹¤ìš´ë¡œë“œ',
        'ì–´ë–¤ ì„œì‹', 'ì–´ë–¤ ì–‘ì‹', 'í•„ìš”í•œ ì„œì‹', 'í•„ìš”í•œ ì–‘ì‹'
    ]
    
    for pattern in form_request_patterns:
        if pattern in query_lower:
            return True
    
    return False

def _determine_search_strategy(query: str, keywords: List[str], estimated_domains: List[str]) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ê³¼ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ê²€ìƒ‰ ì „ëµ ê²°ì •
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ
        estimated_domains: ì¶”ì •ëœ ë„ë©”ì¸
    
    Returns:
        ê²€ìƒ‰ ì „ëµ ë”•ì…”ë„ˆë¦¬
    """
    query_lower = query.lower()
    
    # 0. ì„œì‹ ê´€ë ¨ ì§ˆë¬¸ ìš°ì„  ê²€ì‚¬
    if _is_form_related_query(query, keywords):
        return {
            'type': 'form_specific',
            'confidence': 'high',
            'priority': 'forms_first'
        }
    
    # 1. ë„ë©”ì¸ íŠ¹ì • ê²€ìƒ‰ ì „ëµ
    if estimated_domains and len(estimated_domains) == 1:
        return {
            'type': 'domain_specific',
            'domain': estimated_domains[0],
            'confidence': 'high'
        }
    
    # 2. ë¬¸ì„œ íƒ€ì… íŠ¹ì • ê²€ìƒ‰ ì „ëµ
    doc_type_keywords = {
        'ì •ê´€': ['ì •ê´€', 'ê¸°ë³¸ë²•', 'ì¡°ì§ë²•'],
        'ê·œì •': ['ê·œì •', 'ìš´ì˜ê·œì •', 'ê´€ë¦¬ê·œì •'],
        'ê·œì¹™': ['ê·œì¹™', 'ì„¸ë¶€ê·œì¹™', 'ì‹¤í–‰ê·œì¹™'],
        'ì§€ì¹¨': ['ì§€ì¹¨', 'ì—…ë¬´ì§€ì¹¨', 'ìš´ì˜ì§€ì¹¨']
    }
    
    for doc_type, type_keywords in doc_type_keywords.items():
        if any(keyword in query_lower for keyword in type_keywords):
            return {
                'type': 'file_type_specific',
                'file_type': doc_type,
                'confidence': 'medium'
            }
    
    # 3. ìµœì‹ ì„± ì¸ì‹ ê²€ìƒ‰ ì „ëµ
    recency_keywords = ['ìµœì‹ ', 'ìµœê·¼', 'ìƒˆë¡œìš´', 'ì—…ë°ì´íŠ¸', 'ë³€ê²½', 'ìˆ˜ì •']
    if any(keyword in query_lower for keyword in recency_keywords):
        return {
            'type': 'recency_aware',
            'min_recency': 2,  # ìµœì‹ ì„± ì ìˆ˜ 2 ì´ìƒ
            'confidence': 'medium'
        }
    
    # 4. ë³µí•© ê²€ìƒ‰ ì „ëµ (ê¸°ë³¸)
    return {
        'type': 'hybrid',
        'domain_list': estimated_domains,
        'file_types': None,
        'min_recency': None,
        'confidence': 'low'
    }

def _generate_form_response(query: str, form_results: List[Dict[str, Any]]) -> str:
    """
    ì„œì‹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„œì‹ ì œê³µ ì‘ë‹µ ìƒì„±
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        form_results: ì„œì‹ ê²€ìƒ‰ ê²°ê³¼
    
    Returns:
        ì„œì‹ ì œê³µ ì‘ë‹µ
    """
    if not form_results:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì„œì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ ë³´ì‹œê±°ë‚˜ ê´€ë ¨ ë¶€ì„œì— ë¬¸ì˜í•´ ì£¼ì„¸ìš”."
    
    response_parts = []
    
    # ì„œì‹ ëª©ë¡ êµ¬ì„±
    form_list = []
    for i, result in enumerate(form_results, 1):
        form_title = result.get('form_title', '')
        form_file_uri = result.get('form_file_uri', '')
        source_file = result.get('file_name', '')
        page = result.get('pages', '')
        
        form_info = f"{i}. {form_title}"
        if source_file:
            form_info += f" (ì¶œì²˜: {source_file}"
            if page:
                form_info += f", p.{page}"
            form_info += ")"
        
        form_list.append(form_info)
        
        # S3 íŒŒì¼ ë§í¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if form_file_uri:
            # S3 í‚¤ ì¶”ì¶œ (s3://bucket/key í˜•ì‹ì—ì„œ key ë¶€ë¶„ë§Œ)
            s3_key = form_file_uri.replace('s3://companypolicy/', '')
            # S3 í¼ë¸”ë¦­ URL ì§ì ‘ ìƒì„±
            bucket_name = 'companypolicy'
            region = 'ap-northeast-2'
            download_url = f"https://{bucket_name}.s3.{region}.amazonaws.com/{s3_key}"
            # íŒŒì¼ëª… ì¶”ì¶œ (S3 í‚¤ì—ì„œ ë§ˆì§€ë§‰ ë¶€ë¶„)
            filename = s3_key.split('/')[-1]
            # í´ë¦­ ê°€ëŠ¥í•œ ë§ˆí¬ë‹¤ìš´ ë§í¬ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
            form_list.append(f"  ({download_url})")
    
    # ì‘ë‹µ êµ¬ì„±
    response_parts.append("ìš”ì²­í•˜ì‹  ì„œì‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    response_parts.append("")
    response_parts.extend(form_list)
    response_parts.append("")
    response_parts.append("ğŸ’¡ ì„œì‹ ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­:")
    response_parts.append("- ì„œì‹ì€ ìµœì‹  ë²„ì „ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”")
    response_parts.append("- ì‘ì„± ì „ ê´€ë ¨ ê·œì •ì„ ìˆ™ì§€í•´ ì£¼ì„¸ìš”")
    response_parts.append("- ì œì¶œ ì „ ë‚´ìš©ì„ ë‹¤ì‹œ í•œë²ˆ ê²€í† í•´ ì£¼ì„¸ìš”")
    
    return "\n".join(response_parts)

def _format_form_sources(form_results: List[Dict[str, Any]]) -> List[str]:
    """
    ì„œì‹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì†ŒìŠ¤ ì •ë³´ë¡œ í¬ë§·íŒ…
    
    Args:
        form_results: ì„œì‹ ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        í¬ë§·íŒ…ëœ ì„œì‹ ì†ŒìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    sources = []
    
    for result in form_results:
        form_title = result.get('form_title', '')
        source_file = result.get('file_name', '')
        page = result.get('pages', '')
        form_file_uri = result.get('form_file_uri', '')
        
        source_info = f"ì„œì‹: {form_title}"
        if source_file:
            source_info += f" (ì¶œì²˜: {source_file}"
            if page:
                source_info += f", p.{page}"
            source_info += ")"
        
        if form_file_uri:
            source_info += f" [ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥]"
        
        sources.append(source_info)
    
    return sources

def _format_sources_with_metadata(search_results: List[Dict[str, Any]]) -> List[str]:
    """
    ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì°¸ê³  ë¬¸ì„œ ì •ë³´ í¬ë§·íŒ…
    
    Args:
        search_results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        í¬ë§·íŒ…ëœ ì°¸ê³  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    """
    sources = []
    
    for result in search_results:
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ íŒ¨í„´ ì œê±°
        file_name = result.get('file_name', '')
        if file_name:
            # ë‚ ì§œ íŒ¨í„´ (YYYYMMDD) ì œê±°
            file_name = re.sub(r'\(\d{6}\)', '', file_name).strip()
            file_name = file_name.replace('_', ' ')
        
        # í˜ì´ì§€ ì •ë³´
        page_info = result.get('pages', '')
        if page_info:
            page_str = f"p.{page_info}"
        else:
            page_str = ""
        
        # ë„ë©”ì¸ ì •ë³´
        domain_info = result.get('domain_primary', '')
        if domain_info and domain_info != 'ì¼ë°˜':
            domain_str = f" ({domain_info})"
        else:
            domain_str = ""
        
        # ìµœì‹ ì„± ì •ë³´
        recency_score = result.get('recency_score', 1)
        if recency_score >= 3:
            recency_str = " [ìµœì‹ ]"
        elif recency_score >= 2:
            recency_str = " [ìµœê·¼]"
        else:
            recency_str = ""
        
        # ìµœì¢… ì†ŒìŠ¤ ë¬¸ìì—´ ì¡°í•©
        source_parts = [part for part in [file_name, page_str, domain_str, recency_str] if part]
        source_str = " ".join(source_parts).strip()
        
        if source_str:
            sources.append(source_str)
    
    return sources

def quick_search(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    ë¹ ë¥¸ ê²€ìƒ‰ (ë‹µë³€ ìƒì„± ì—†ì´)
    
    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸
        top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    try:
        searcher = RagSearcher()
        results = searcher.search(query, top_k=top_k)
        return results
    except Exception as e:
        logger.error(f"ë¹ ë¥¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        print(f"ë¹ ë¥¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

def get_domain_suggestions(query: str) -> List[str]:
    """
    ì§ˆë¬¸ì— ëŒ€í•œ ë„ë©”ì¸ ì œì•ˆ
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
    
    Returns:
        ì œì•ˆ ë„ë©”ì¸ ë¦¬ìŠ¤íŠ¸
    """
    try:
        keywords = extract_keywords(query)
        suggestions = guess_domains_from_keywords(keywords)
        return suggestions
    except Exception as e:
        logger.error(f"ë„ë©”ì¸ ì œì•ˆ ì˜¤ë¥˜: {e}")
        print(f"ë„ë©”ì¸ ì œì•ˆ ì˜¤ë¥˜: {e}")
        return []

def health_check() -> Dict[str, Any]:
    """
    RAG ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    
    Returns:
        ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
    """
    try:
        searcher = RagSearcher()
        
        # Qdrant ì—°ê²° ìƒíƒœ í™•ì¸
        qdrant_health = searcher.health_check()
        
        # ì»¬ë ‰ì…˜ ì •ë³´ ì¡°íšŒ
        collection_info = searcher.get_collection_info()
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        keyword_test = extract_keywords("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
        
        return {
            'status': 'healthy' if all([qdrant_health, collection_info, keyword_test]) else 'degraded',
            'qdrant_connection': qdrant_health,
            'collection_info': collection_info,
            'keyword_extraction': bool(keyword_test),
            'timestamp': datetime.datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        return {
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.datetime.now().isoformat()
        }

def rag_answer_enhanced(user_query: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
    """
    í–¥ìƒëœ RAG ë‹µë³€ ìƒì„± (ë©€í‹°í„´ ëŒ€í™” ì§€ì›)
    
    Args:
        user_query: ì‚¬ìš©ì ì§ˆë¬¸
        conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
    
    Returns:
        ë‹µë³€ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ ê²°ê³¼
    """
    try:
        # OpenAI API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜´
        result = answer_query(user_query, conversation_history=conversation_history)
        
        # answer_queryëŠ” í•­ìƒ answerë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ success ì²´í¬ ë¶ˆí•„ìš”
        search_strategy = result.get('search_strategy', '')
        
        return {
            'answer': result.get('answer', 'ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'),
            'sources': result.get('sources', []),
            'rag_used': search_strategy != 'simple_response',  # ê°„ë‹¨í•œ ì‘ë‹µì´ ì•„ë‹ˆë©´ RAG ì‚¬ìš©
            'metadata': {
                'domains': result.get('domains', []),
                'search_strategy': search_strategy,
                'keywords': result.get('keywords', []),
                'total_time': result.get('total_time', 0),
                'search_time': result.get('search_time', 0),
                'answer_time': result.get('answer_time', 0),
                'conversation_history_used': bool(conversation_history)
            }
        }
            
    except Exception as e:
        logger.error(f"í–¥ìƒëœ RAG ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        print(f"í–¥ìƒëœ RAG ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
        return {
            'answer': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'sources': [],
            'rag_used': False,
            'metadata': {'error': str(e)}
        }